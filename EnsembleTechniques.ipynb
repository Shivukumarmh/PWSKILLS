{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**Ensemble Learning**\n",
        "##Assignment Questions\n",
        "\n",
        "\n",
        "\n",
        "##Theoretical\n",
        "\n",
        "1. Can we use Bagging for regression problems?\n",
        "  - Yes (VotingRegressor)\n",
        "\n",
        "2. What is the difference between multiple model training and single model training?\n",
        "  - Multiple model training : Here multiple models are trained could be of same algorithm or of different algorithm.\n",
        "  - Single model training : Here only the single model is been trained.\n",
        "\n",
        "3. Explain the concept of feature randomness in Random Forest.\n",
        "  - So in feature randomness , it selects the random features of the dataset for each model with the replacement.\n",
        "\n",
        "4. What is OOB (Out-of-Bag) Score?\n",
        "  - The Out-of-Bag (OOB) score is a technique used in ensemble learning, to assess the performance of the model without the need for a separate validation or test set.\n",
        "  - It basically calculates the preformance of the model while training before going to testing.\n",
        "\n",
        "5. How can you measure the importance of features in a Random Forest model?\n",
        "  - Using  \"feature_importances_\"\n",
        "\n",
        "6. Explain the working principle of a Bagging Classifier\n",
        "  - It works on the parallel ensamble techinique.\n",
        "  - It combines the predictions of multiple base models  to produce a more accurate and robust final prediction.\n",
        "\n",
        "7. How do you evaluate a Bagging Classifierâ€™s performance?\n",
        "  - Using accuracy , confusion metrix\n",
        "\n",
        "8. How does a Bagging Regressor work?\n",
        "  - A Bagging Regressor is an ensemble learning technique used to improve the performance of regression models by combining the predictions of multiple base models.\n",
        "\n",
        "9. What is the main advantage of ensemble techniques?\n",
        "  - To reduce the overfitting of models.\n",
        "  - To make the models more stable.\n",
        "  - To increase the accuracy.\n",
        "\n",
        "10. What is the main challenge of ensemble methods?\n",
        "  - More time complexity\n",
        "  - More space complexity\n",
        "  - Overfitting\n",
        "  - Interpretability\n",
        "\n",
        "11. Explain the key idea behind ensemble techniques.\n",
        "  - To combine the predictions of various weak model to give the final prediction.\n",
        "\n",
        "12. What is a Random Forest Classifier\n",
        "  -  It is used for classification tasks and is based on the idea of constructing a collection of decision trees during training and outputting the class that is the mode of the classes predicted by individual trees.\n",
        "\n",
        "13. What are the main types of ensemble techniques?\n",
        "  - Parallel techniques\n",
        "  - Sequential techniques\n",
        "  - Parallel + Sequential techniques\n",
        "\n",
        "14. What is ensemble learning in machine learning?\n",
        "   - It is to combining the predictions of various weak models to arrive at the best output.\n",
        "   - To leverage the diversity of multiple models to make more accurate predictions than any individual model alone.\n",
        "\n",
        "15. When should we avoid using ensemble methods?\n",
        "  - When Model Interpretability is Crucial\n",
        "  - When Computational Resources Are Limited\n",
        "  - When You Have Limited Data\n",
        "  - When we need the simple model\n",
        "\n",
        "16. How does Bagging help in reducing overfitting?\n",
        "  - Bagging works by training multiple base learners  on different random subsets of the training data. These base learners are independent of each other, and their predictions are combined to form the final result .\n",
        "\n",
        "17. Why is Random Forest better than a single Decision Tree?\n",
        "  - Because it gives the answer by majority of the various models.\n",
        "\n",
        "18. What is the role of bootstrap sampling in Bagging?\n",
        "  - The role of bootstrap sampling in Bagging (Bootstrap Aggregating) is crucial to its ability to reduce variance and improve the overall performance of the ensemble model.\n",
        "\n",
        "19. What are some real-world applications of ensemble techniques?\n",
        "  - Healthcare & Medical Diagnosis\n",
        "  - Finance & Risk Management\n",
        "  - Image & Speech Recognition\n",
        "\n",
        "20. What is the difference between Bagging and Boosting?\n",
        "  - Bagging : It is the parallel ensemble technique.\n",
        "  - Boosting : It is the sequential ensemble technique."
      ],
      "metadata": {
        "id": "DJ6ypFjWXTiQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Practical"
      ],
      "metadata": {
        "id": "XmoS-XF4cLRJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#21. Train a Bagging Classifier using Decision Trees on a sample dataset and print model accuracy2\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "X, Y = make_classification(n_samples=1000, n_features=10, n_classes=2, n_informative=3)\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=1)\n",
        "\n",
        "model = BaggingClassifier(estimator=DecisionTreeClassifier(), n_estimators=10, random_state=1)\n",
        "\n",
        "\n",
        "model.fit(X_train, Y_train)\n",
        "Y_pred = model.predict(X_test)\n",
        "\n",
        "\n",
        "accuracy = accuracy_score(Y_test, Y_pred)\n",
        "print(f\"Model Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3MoWGvbIcQTT",
        "outputId": "e6c0f608-d11e-4c9a-c95e-676a55f1e2cd"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 0.8850\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#22. Train a Bagging Regressor using Decision Trees and evaluate using Mean Squared Error (MSE)\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import BaggingRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "X, Y = make_regression(n_samples=1000, n_features=10, n_informative=3)\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=1)\n",
        "\n",
        "\n",
        "model = BaggingRegressor(estimator=DecisionTreeRegressor(), n_estimators=10, random_state=1)\n",
        "model.fit(X_train, Y_train)\n",
        "\n",
        "Y_pred = model.predict(X_test)\n",
        "\n",
        "mse = mean_squared_error(Y_test, Y_pred)\n",
        "print(\"Mean Squared Error is\", mse)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OABlLIbEnuf9",
        "outputId": "5bbcb7e5-f044-4dc7-bb03-cf7727f2a463"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error is 459.1721049852483\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#23. Train a Random Forest Classifier on the Breast Cancer dataset and print feature importance scores2\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "df=load_breast_cancer()\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(df.data, df.target, test_size=0.2, random_state=1)\n",
        "\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=1)\n",
        "model.fit(X_train, Y_train)\n",
        "\n",
        "feature_importance = model.feature_importances_\n",
        "print(feature_importance)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UOyaHcP5otHy",
        "outputId": "624795ff-5a2b-47d7-b7d8-c6450288223e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.06811959 0.01895654 0.06651358 0.04562212 0.00559711 0.0050085\n",
            " 0.05854792 0.09173071 0.00249771 0.00226877 0.02215035 0.0035935\n",
            " 0.00779888 0.0288948  0.00429829 0.00313988 0.00286557 0.00498554\n",
            " 0.00458959 0.00526312 0.08431373 0.01757519 0.13077297 0.11767767\n",
            " 0.00914248 0.01092473 0.03087749 0.13030665 0.00923893 0.00672809]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#24.  Train a Random Forest Regressor and compare its performance with a single Decision Tree\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "X, Y = make_regression(n_samples=1000, n_features=10, n_informative=3)\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=1)\n",
        "\n",
        "dt=DecisionTreeRegressor()\n",
        "dt.fit(X_train, Y_train)\n",
        "Y_pred = dt.predict(X_test)\n",
        "mse = mean_squared_error(Y_test, Y_pred)\n",
        "print(\"Mean Squared Error is\", mse)\n",
        "\n",
        "rf = RandomForestRegressor(n_estimators=100, random_state=1)\n",
        "rf.fit(X_train, Y_train)\n",
        "Y_pred = rf.predict(X_test)\n",
        "mse = mean_squared_error(Y_test, Y_pred)\n",
        "print(\"Mean Squared Error is\", mse)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8PqeXLFpMmo",
        "outputId": "8f1b5260-e2c9-4163-dfc7-993a0ddd951a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error is 1288.0720353095153\n",
            "Mean Squared Error is 427.3132147826008\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#25. Compute the Out-of-Bag (OOB) Score for a Random Forest Classifier\n",
        "\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "X, Y = make_classification(n_samples=1000, n_features=10, n_classes=2, n_informative=3)\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size=0.3,random_state=1)\n",
        "\n",
        "model = RandomForestClassifier(oob_score=True)\n",
        "model.fit(X_train,Y_train)\n",
        "\n",
        "oob_score = model.oob_score_\n",
        "print(\"OOB Score is\", oob_score)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nFyvxnWCpsZs",
        "outputId": "f961c01e-c7be-48fc-e6ff-be73c21968ce"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OOB Score is 0.9014285714285715\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#26. Train a Bagging Classifier using SVM as a base estimator and print accuracy2\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "X, y = make_classification(n_samples=1000, n_features=10, n_classes=2, n_informative=3)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "model = SVC()\n",
        "bag_clf = BaggingClassifier(estimator=model, n_estimators=100,bootstrap=True, random_state=42)\n",
        "\n",
        "bag_clf.fit(X_train, y_train)\n",
        "y_pred = bag_clf.predict(X_test)\n",
        "\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sT4AXXUbqC00",
        "outputId": "64c8e0a3-e48f-429e-94a3-8392a1c5f418"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.93\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#27. Train a Random Forest Classifier with different numbers of trees and compare accuracy\n",
        "\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "X,Y=make_classification(n_samples=1000,n_features=10,n_classes=2,n_informative=3)\n",
        "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2,random_state=1)\n",
        "\n",
        "model=RandomForestClassifier(n_estimators=20,random_state=1)\n",
        "model.fit(X_train,Y_train)\n",
        "Y_pred=model.predict(X_test)\n",
        "print(\"Accuracy is\",accuracy_score(Y_test,Y_pred))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hyghrbnSqT-H",
        "outputId": "1c242e92-a113-4181-ec17-290506435399"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy is 0.91\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#28. Train a Bagging Classifier using Logistic Regression as a base estimator and print AUC score\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "X,Y=make_classification(n_classes=2,n_samples=1000,n_features=10,n_informative=3)\n",
        "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.30,random_state=1)\n",
        "\n",
        "model=LogisticRegression()\n",
        "bag_clf=BaggingClassifier(estimator=model,n_estimators=100,bootstrap=True,random_state=1)\n",
        "\n",
        "bag_clf.fit(X_train,Y_train)\n",
        "\n",
        "Y_pred=bag_clf.predict(X_test)\n",
        "print(roc_auc_score(Y_test,Y_pred))\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94lR5tOwrHNX",
        "outputId": "b53cfd81-f143-4556-c6d2-7477ac9cabc0"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.49333333333333335\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#29. Train a Random Forest Regressor and analyze feature importance scores\n",
        "\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "X,Y=make_regression(n_samples=1000,n_features=10,n_informative=3)\n",
        "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.30,random_state=1)\n",
        "\n",
        "model=RandomForestRegressor(n_estimators=100,random_state=1)\n",
        "model.fit(X_train,Y_train)\n",
        "\n",
        "feature_importance=model.feature_importances_\n",
        "print(feature_importance)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IufSAeT8rYXE",
        "outputId": "9b38f06a-5d1d-4b31-a84f-2021ae5c2624"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.31842091 0.00515865 0.47750956 0.0062983  0.0043804  0.16958632\n",
            " 0.00426773 0.00418382 0.0057306  0.0044637 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#30. Train an ensemble model using both Bagging and Random Forest and compare accuracy.\n",
        "\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "X, Y = make_classification(n_samples=1000, n_features=10, n_classes=2, n_informative=3)\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=1)\n",
        "\n",
        "bag_clf = BaggingClassifier(n_estimators=100, random_state=1)\n",
        "bag_clf.fit(X_train, Y_train)\n",
        "Y_pred_bag = bag_clf.predict(X_test)\n",
        "\n",
        "rf_clf = RandomForestClassifier(n_estimators=100, random_state=1)\n",
        "rf_clf.fit(X_train, Y_train)\n",
        "Y_pred_rf = rf_clf.predict(X_test)\n",
        "\n",
        "print(\"Bagging Accuracy:\", accuracy_score(Y_test, Y_pred_bag))\n",
        "print(\"Random Forest Accuracy:\", accuracy_score(Y_test, Y_pred_rf))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y3epoQZerrXL",
        "outputId": "c0f58412-8e9a-4d8b-9b48-b4e53eefd7f3"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bagging Accuracy: 0.915\n",
            "Random Forest Accuracy: 0.915\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#31.  Train a Random Forest Classifier and tune hyperparameters using GridSearchCV\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "X, y = make_classification(n_samples=1000, n_features=10, n_classes=2, n_informative=3)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 150],\n",
        "    'max_depth': [5, 10, 15],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "best_rf = grid_search.best_estimator_\n",
        "y_pred = best_rf.predict(X_test)\n",
        "\n",
        "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pN4LBWldr2H2",
        "outputId": "345e7913-71fc-4883-86ba-c00a5b04df2e"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Hyperparameters: {'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 100}\n",
            "Accuracy: 0.84\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#32.  Train a Bagging Regressor with different numbers of base estimators and compare performance.\n",
        "\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import BaggingRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "X, y = make_regression(n_samples=1000, n_features=10, n_informative=5, noise=0.1, random_state=42)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "estimators_list = [10, 50, 100, 150]\n",
        "for n in estimators_list:\n",
        "    model = BaggingRegressor(estimator=DecisionTreeRegressor(), n_estimators=n, random_state=42)\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    print(f\"n_estimators = {n}, MSE = {mse:.4f}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49yzqNlrsvzW",
        "outputId": "8bba83cd-b0d4-4f72-ad66-5a1aeda633b0"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_estimators = 10, MSE = 247.5151\n",
            "n_estimators = 50, MSE = 213.3602\n",
            "n_estimators = 100, MSE = 209.4471\n",
            "n_estimators = 150, MSE = 211.5226\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#33. Train a Random Forest Classifier and analyze misclassified samples\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "iris = load_iris()\n",
        "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.2, random_state=1)\n",
        "\n",
        "clf=RandomForestClassifier()\n",
        "clf.fit(X_train,y_train)\n",
        "y_pred=clf.predict(X_test)\n",
        "\n",
        "print(classification_report(y_test,y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XBTA6QZftPMZ",
        "outputId": "32dabb08-91a4-41ae-a204-d505db322e1a"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        11\n",
            "           1       1.00      0.92      0.96        13\n",
            "           2       0.86      1.00      0.92         6\n",
            "\n",
            "    accuracy                           0.97        30\n",
            "   macro avg       0.95      0.97      0.96        30\n",
            "weighted avg       0.97      0.97      0.97        30\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#34. = Train a Bagging Classifier and compare its performance with a single Decision Tree Classifier.\n",
        "\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "X, Y = make_classification(n_samples=1000, n_features=10, n_classes=2, n_informative=3)\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=1)\n",
        "\n",
        "model = BaggingClassifier(estimator=DecisionTreeClassifier(), n_estimators=10, random_state=1)\n",
        "model.fit(X_train, Y_train)\n",
        "Y_pred = model.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(Y_test, Y_pred)\n",
        "print(\"Bagging Classifier Accuracy:\", accuracy)\n",
        "\n",
        "\n",
        "model=DecisionTreeClassifier()\n",
        "model.fit(X_train,Y_train)\n",
        "Y_pred=model.predict(X_test)\n",
        "accuracy=accuracy_score(Y_test,Y_pred)\n",
        "print(\"Decision Tree Classifier Accuracy:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sU_RsTo8tjix",
        "outputId": "b9e37062-9526-4a15-8475-b851899d823c"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bagging Classifier Accuracy: 0.88\n",
            "Decision Tree Classifier Accuracy: 0.85\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#35.  Train a Random Forest Classifier and visualize the confusion matrix\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "X,Y=make_classification(n_samples=1000,n_features=10,n_classes=2,n_informative=3)\n",
        "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2,random_state=1)\n",
        "\n",
        "model=RandomForestClassifier()\n",
        "model.fit(X_train,Y_train)\n",
        "Y_pred=model.predict(X_test)\n",
        "\n",
        "cm=confusion_matrix(Y_test,Y_pred)\n",
        "sns.heatmap(cm,annot=True,fmt='d')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "cqanW5hUuF_x",
        "outputId": "7810dd70-ebf6-4d20-f2af-6b3dd9397463"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#36. Train a Stacking Classifier using Decision Trees, SVM, and Logistic Regression, and compare accuracy\n",
        "\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, n_classes=2, random_state=42)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "estimators = [\n",
        "    ('dt', DecisionTreeClassifier(random_state=42)),\n",
        "    ('svm', SVC(probability=True, random_state=42))\n",
        "]\n",
        "\n",
        "stack_model = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression(), cv=5)\n",
        "stack_model.fit(X_train, y_train)\n",
        "y_pred = stack_model.predict(X_test)\n",
        "print(\"Stacking Classifier Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gws9EF15uX4J",
        "outputId": "61b6fe12-0576-42c1-a1a7-4d1ffc452117"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stacking Classifier Accuracy: 0.935\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#37. Train a Random Forest Classifier and print the top 5 most important features=\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X,Y=make_classification(n_samples=1000,n_features=10,n_classes=2,n_informative=3)\n",
        "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2,random_state=1)\n",
        "\n",
        "model=RandomForestClassifier()\n",
        "model.fit(X_train,Y_train)\n",
        "\n",
        "feature_importances=model.feature_importances_\n",
        "sorted_indices=sorted(range(len(feature_importances)),key=lambda i:feature_importances[i],reverse=True)\n",
        "\n",
        "top_5_indices=sorted_indices[:5]\n",
        "top_5_features=[f\"Feature {i+1}\" for i in top_5_indices]\n",
        "print(top_5_features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fYY3LIwVuls7",
        "outputId": "b73a5a7e-1c15-4dc5-c02c-9fae0894d6f9"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Feature 5', 'Feature 10', 'Feature 9', 'Feature 6', 'Feature 3']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#38.  Train a Bagging Classifier and evaluate performance using Precision, Recall, and F1-score\n",
        "\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score\n",
        "\n",
        "X, Y = make_classification(n_samples=1000, n_features=10, n_classes=2, n_informative=3)\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=1)\n",
        "\n",
        "model = BaggingClassifier(estimator=DecisionTreeClassifier(), n_estimators=10, random_state=1)\n",
        "model.fit(X_train, Y_train)\n",
        "Y_pred = model.predict(X_test)\n",
        "\n",
        "print(\"Accuracy\",accuracy_score(Y_test,Y_pred))\n",
        "print(\"Precision\",precision_score(Y_test,Y_pred))\n",
        "print(\"Recall\",recall_score(Y_test,Y_pred))\n",
        "print(\"F1 Score\",f1_score(Y_test,Y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nflVNLhZuzD2",
        "outputId": "8dfc84b0-98f4-4a35-eac2-f6dbf9443c93"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy 0.935\n",
            "Precision 0.9174311926605505\n",
            "Recall 0.9615384615384616\n",
            "F1 Score 0.9389671361502347\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#39. Train a Random Forest Classifier and analyze the effect of max_depth on accuracy\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "X, Y = make_classification(n_samples=1000, n_features=10, n_classes=2, n_informative=3)\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=1)\n",
        "\n",
        "max_depth_values = [5, 10, 15, 20]\n",
        "for max_depth in max_depth_values:\n",
        "    model = RandomForestClassifier(n_estimators=100, max_depth=max_depth, random_state=1)\n",
        "    model.fit(X_train, Y_train)\n",
        "    Y_pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(Y_test, Y_pred)\n",
        "    print(f\"Max Depth: {max_depth}, Accuracy: {accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_mI0Wi_vJsF",
        "outputId": "a063624f-8757-462c-b467-df293ba2a2cd"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max Depth: 5, Accuracy: 0.9150\n",
            "Max Depth: 10, Accuracy: 0.9500\n",
            "Max Depth: 15, Accuracy: 0.9550\n",
            "Max Depth: 20, Accuracy: 0.9600\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#40.  Train a Bagging Regressor using different base estimators (DecisionTree and KNeighbors) and compare performance\n",
        "\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import BaggingRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "X, Y = make_regression(n_samples=1000, n_features=10, n_informative=3)\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=1)\n",
        "\n",
        "base_estimators = [\n",
        "    ('dt', DecisionTreeRegressor(random_state=1)),\n",
        "    ('knn', KNeighborsRegressor())\n",
        "]\n",
        "\n",
        "for estimator_name, estimator in base_estimators:\n",
        "    model = BaggingRegressor(estimator=estimator, n_estimators=10, random_state=1)\n",
        "    model.fit(X_train, Y_train)\n",
        "    Y_pred = model.predict(X_test)\n",
        "    mse = mean_squared_error(Y_test, Y_pred)\n",
        "    print(model,mse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_PEHkCTkvZlB",
        "outputId": "abc71713-b5d4-4401-adfa-728d97c3875c"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BaggingRegressor(estimator=DecisionTreeRegressor(random_state=1),\n",
            "                 random_state=1) 236.69081747220204\n",
            "BaggingRegressor(estimator=KNeighborsRegressor(), random_state=1) 1865.0410470667503\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#41. Train a Random Forest Classifier and evaluate its performance using ROC-AUC Score\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "X,Y=make_classification(n_samples=1000,n_features=10,n_classes=2,n_informative=3)\n",
        "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2,random_state=1)\n",
        "\n",
        "model=RandomForestClassifier()\n",
        "model.fit(X_train,Y_train)\n",
        "Y_pred=model.predict(X_test)\n",
        "\n",
        "roc_auc=roc_auc_score(Y_test,Y_pred)\n",
        "print(roc_auc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bT6Oli9cvqP6",
        "outputId": "0987271c-4f86-4cb6-9fc8-0e5a224b1165"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.965\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#42. Train a Bagging Classifier and evaluate its performance using cross-validatio.\n",
        "\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "X, Y = make_classification(n_samples=1000, n_features=10, n_classes=2, n_informative=3)\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=1)\n",
        "\n",
        "model = BaggingClassifier(estimator=DecisionTreeClassifier(), n_estimators=10, random_state=1)\n",
        "scores = cross_val_score(model, X_train, Y_train, cv=5)\n",
        "print(scores)\n",
        "print(scores.mean())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xp4km2lLv1bp",
        "outputId": "bdb8577f-b969-4f5d-8e83-4cb33dc93a67"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.80625 0.8375  0.86875 0.85    0.83125]\n",
            "0.8387500000000001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#43.  Train a Random Forest Classifier and plot the Precision-Recall curve\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "X, Y = make_classification(n_samples=1000, n_features=10, n_classes=2, n_informative=3)\n",
        "X_train, X_test, Y_train, Y_test=train_test_split(X,Y,test_size=0.2,random_state=1)\n",
        "\n",
        "model=RandomForestClassifier()\n",
        "model.fit(X_train,Y_train)\n",
        "Y_pred=model.predict(X_test)\n",
        "\n",
        "precision,recall,_=precision_recall_curve(Y_test,Y_pred)\n",
        "plt.plot(recall,precision)\n",
        "plt.xlabel(\"Recall\")\n",
        "plt.ylabel(\"Precision\")\n",
        "plt.title(\"Precision-Recall Curve\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "AWp21Gc2wEAI",
        "outputId": "209fba67-c9fa-43dc-af64-a51b7d547fe9"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#44. Train a Stacking Classifier with Random Forest and Logistic Regression and compare accuracy\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, n_classes=2, random_state=1)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
        "\n",
        "estimators = [\n",
        "    ('rf', RandomForestClassifier(n_estimators=100, random_state=1)),\n",
        "    ('lr', LogisticRegression(random_state=1))\n",
        "]\n",
        "\n",
        "stack_model = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression())\n",
        "stack_model.fit(X_train, y_train)\n",
        "y_pred = stack_model.predict(X_test)\n",
        "print(\"Stacking Classifier Accuracy:\", accuracy_score(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IG91D9BiwW3U",
        "outputId": "9bdb4f6c-1b64-4c09-96d3-c78870641f1f"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stacking Classifier Accuracy: 0.92\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#45. Train a Bagging Regressor with different levels of bootstrap samples and compare performance\n",
        "\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import BaggingRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "X,Y=make_regression(n_samples=1000,n_features=10,random_state=1)\n",
        "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2,random_state=1)\n",
        "\n",
        "bootstrap_samples=[0.1,0.2,0.3,0.4,0.5]\n",
        "for sample in bootstrap_samples:\n",
        "    model=BaggingRegressor(estimator=DecisionTreeRegressor(),n_estimators=10,bootstrap_features=True)\n",
        "    model.fit(X_train,Y_train)\n",
        "    Y_pred=model.predict(X_test)\n",
        "    mse=mean_squared_error(Y_test,Y_pred)\n",
        "    print(f\"Bootstrap Samples: {sample}, MSE: {mse}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6qzlktlDwmF2",
        "outputId": "8beda0fc-3c3b-4856-b859-4840d03a8c70"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bootstrap Samples: 0.1, MSE: 5619.994352817058\n",
            "Bootstrap Samples: 0.2, MSE: 5449.024769037371\n",
            "Bootstrap Samples: 0.3, MSE: 11947.857988574906\n",
            "Bootstrap Samples: 0.4, MSE: 8544.24800875386\n",
            "Bootstrap Samples: 0.5, MSE: 10459.742644411968\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TtdO4uyAw8LU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}